{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "historic_hu = pd.read_csv('data/historic/HB_HOUSTON.csv')\n",
    "live_hu = pd.read_csv('data/live/HB_HOUSTON.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_data(df):\n",
    "    '''\n",
    "    Convert DeliveryDate, DeliveryHour and DeliveryInterval column to pd.to_datetime. Also remove the DSTFlag and SettlementPointType column. \n",
    "    Also arranges in ascending order\n",
    "    '''\n",
    "    df['Date'] = pd.to_datetime(df['DeliveryDate']) + df['DeliveryHour'].astype('timedelta64[h]') + ((df['DeliveryInterval'] - 1) * 15).astype('timedelta64[m]')\n",
    "    df = df.drop(columns=['DeliveryDate', 'DeliveryHour', 'DeliveryInterval', 'DSTFlag', 'SettlementPointType', 'SettlementPointName'], axis=1)\n",
    "    df = df.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "    return df[['Date', 'SettlementPointPrice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "live = fix_data(live_hu)\n",
    "historic = fix_data(historic_hu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixJoin(live, historic):\n",
    "    '''\n",
    "    Drop Duplicates and fix missing timelines\n",
    "    '''\n",
    "    \n",
    "    df = pd.concat([live, historic]).sort_values('Date')\n",
    "    dupShape = df.shape[0]\n",
    "\n",
    "    df = df.drop_duplicates('Date').reset_index(drop=True)\n",
    "    duplicates = dupShape - df.shape[0]\n",
    "    print(\"Total Duplicates: {}\".format(duplicates))\n",
    "    \n",
    "    totalMissing = sum((df['Date'].shift(-1)[:-1] - df['Date'][:-1]).astype('timedelta64[m]') != 15)\n",
    "    \n",
    "    print(\"Total Missing Dates: {}\".format(totalMissing))\n",
    "    missingDates = list(df[:-1][(df['Date'].shift(-1)[:-1] - df['Date'][:-1]).astype('timedelta64[m]') != 15]['Date'])\n",
    "    print(\"The Missing dates are around: {}\".format(missingDates))\n",
    "    \n",
    "    dates = pd.DataFrame(pd.date_range(df.iloc[0]['Date'],df.iloc[-1]['Date'],freq='15T'))\n",
    "    dates.columns = ['Date']\n",
    "    \n",
    "    df.set_index('Date', inplace=True)\n",
    "    dates.set_index('Date', inplace=True)\n",
    "    \n",
    "    full_data = pd.concat([df, dates], axis=1).fillna(method='ffill')\n",
    "    full_data.index.name = 'Date'\n",
    "    \n",
    "    return full_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Duplicates: 22393\n",
      "Total Missing Dates: 8\n",
      "The Missing dates are around: [Timestamp('2011-03-13 02:45:00'), Timestamp('2012-03-11 02:45:00'), Timestamp('2013-03-10 02:45:00'), Timestamp('2014-03-09 02:45:00'), Timestamp('2015-03-08 02:45:00'), Timestamp('2016-03-13 02:45:00'), Timestamp('2017-03-12 02:45:00'), Timestamp('2018-03-11 02:45:00')]\n"
     ]
    }
   ],
   "source": [
    "df = fixJoin(live, historic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
